# HOI paper
##  CVPR2023
1. Relational Context Learning for Human-Object Interaction Detection[[paper]](https://arxiv.org/abs/2304.04997)[[code]](https://github.com/OreoChocolate/MUREN)
2. Category Query Learning for Human-Object Interaction Classification[[paper]](https://arxiv.org/abs/2303.14005)[[code]](https://github.com/charles-xie/CQL)
3. ViPLO: Vision Transformer based Pose-Conditioned Self-Loop Graph for Human-Object Interaction Detection[[paper]](https://arxiv.org/abs/2304.08114v1)[[code]](https://github.com/Jeeseung-Park/ViPLO)
4. HOICLIP: Efficient Knowledge Transfer for HOI Detection with Vision-Language Models[[paper]](https://arxiv.org/abs/2303.15786)[[code]](https://github.com/Artanic30/HOICLIP)

## CVPR2022
1. Human-Object Interaction Detection via Disentangled Transformer[[paper]](https://arxiv.org/abs/2204.09290)
2. Distillation Using Oracle Queries for Transformer-based Human-Object Interaction Detection[[paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Qu_Distillation_Using_Oracle_Queries_for_Transformer-Based_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf)[[code]](https://github.com/SherlockHolmes221/DOQ)
3. Efficient Two-Stage Detection of Human-Object Interactions with a Novel Unary-Pairwise Transformer[[paper]](https://arxiv.org/abs/2112.01838v1)[[code]](https://github.com/fredzzhang/upt)
